{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74ecc173-2f44-4082-9cdb-dbca53180ee9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#importing libararies\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, DateType, DoubleType, StringType, IntegerType\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler \n",
    "from pyspark.ml import Pipeline \n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Import the logistic regression model \n",
    "from pyspark.ml.regression import LinearRegression, LinearRegressionModel\n",
    "# Import the evaluation module \n",
    "from pyspark.ml.evaluation import * \n",
    "# Import the model tuning module \n",
    "from pyspark.ml.tuning import * \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import lead\n",
    "from pyspark.sql.window import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3a613b7-ced2-4fd0-a687-0711444f536d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Getting all the file name using boto3 \n",
    "\n",
    "# Set up AWS credentials\n",
    "aws_access_key_id = {\"Your acess key\"}\n",
    "aws_secret_access_key = {\"Your secret key\"}\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key\n",
    ")\n",
    "#adding buxket name and folder\n",
    "bucket_name = 'stockprediction-wg'\n",
    "folder_prefix = 'landing/'\n",
    "\n",
    "s3 = session.client('s3')\n",
    "# List objects within the landing \"folder\"\n",
    "objects = s3.list_objects(Bucket=bucket_name, Prefix=folder_prefix)\n",
    "\n",
    "#creating training and testing dataset\n",
    "csv = []\n",
    "training = []\n",
    "testing = []\n",
    "\n",
    "for obj in objects.get('Contents', []):\n",
    "    key = obj['Key']\n",
    "    if key.endswith(\".csv\"):\n",
    "        csv.append(key)\n",
    "\n",
    "print(csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a5986f1-5cde-487d-9556-6bf4f845728b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# To work with Amazon S3 storage, set the following variables using your AWS Access Key and Secret Key\n",
    "# Set the Region to where your files are stored in S3.\n",
    "access_key = {\"Your acess key\"}\n",
    "secret_key = {\"Your secret key\"}\n",
    "# Set the environment variables so boto3 can pick them up later\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = access_key\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = secret_key\n",
    "encoded_secret_key = secret_key.replace(\"/\", \"%2F\")\n",
    "aws_region = \"us-east-2\"\n",
    "# Update the Spark options to work with our AWS Credentials\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", access_key)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secret_key)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.\" + aws_region +\".amazonaws.com\")\n",
    "\n",
    "#Creating list for datat frame to be combine\n",
    "sdf_list=[]\n",
    "\n",
    "# for file_path in csv:\n",
    "file_path1 = \"s3a://stockprediction-wg/landing/\"\n",
    "sdf = spark.read.csv(file_path1, header=True, inferSchema=True)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b4d18c4-1441-4587-ad9a-767c6a793f15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab88c659-4606-489f-9963-ae274e90cf55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "type(sdf)\n",
    "sdf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18805943-2519-4193-9bf3-f8e68805402a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Clean data phase\n",
    "#Removing all duplicate dates\n",
    "NDsdf = sdf.dropDuplicates([\"Dates\",\"Symbol\"])\n",
    "\n",
    "# remove all null value\n",
    "Nsdf = NDsdf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a16c32a8-62de-407c-84c8-3a0149cb3171",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(Nsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e045119-d631-420c-b136-ae5ae4ddb3ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Apply schema to column\n",
    "Nsdf=Nsdf.withColumn(\"Dates\", col(\"Dates\").cast(DateType()))\n",
    "Nsdf=Nsdf.withColumn(\"Open\", col(\"Open\").cast(\"double\"))\n",
    "Nsdf=Nsdf=Nsdf.withColumn(\"High\", col(\"High\").cast(\"double\"))\n",
    "Nsdf=Nsdf.withColumn(\"Low\", col(\"Low\").cast(\"double\"))\n",
    "Nsdf=Nsdf.withColumn(\"Close\", col(\"Close\").cast(\"double\"))\n",
    "Nsdf=Nsdf.withColumn(\"Volume\", col(\"Volume\").cast(\"double\"))\n",
    "Nsdf=Nsdf.withColumn(\"MSFT\", col(\"MSFT\").cast(\"integer\"))\n",
    "Nsdf=Nsdf.withColumn(\"AAPL\", col(\"AAPL\").cast(\"integer\"))\n",
    "Nsdf=Nsdf.withColumn(\"GOOG\", col(\"GOOG\").cast(\"integer\"))\n",
    "Nsdf=Nsdf.withColumn(\"META\", col(\"META\").cast(\"integer\"))\n",
    "Nsdf=Nsdf.withColumn(\"IBM\", col(\"IBM\").cast(\"integer\"))\n",
    "Nsdf=Nsdf.withColumn(\"AMZN\", col(\"AMZN\").cast(\"integer\"))\n",
    "Nsdf=Nsdf.withColumn(\"RSI\", col(\"RSI\").cast(\"double\"))\n",
    "Nsdf=Nsdf.withColumn(\"EMA\", col(\"EMA\").cast(\"double\"))\n",
    "Nsdf=Nsdf.withColumn(\"OBV\", col(\"OBV\").cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80e86c78-8976-4cb3-988a-db0ca0a584b9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sgdata_sdf = spark.read.csv(\"s3a://stockprediction-wg/landing/StormGuardData.csv\", header=True, inferSchema=True)\n",
    "display(sgdata_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d0d4bf0-792d-4ebb-a624-1eaf2984bd05",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#rename date column in Nsdf so it can be merge\n",
    "Nsdf = Nsdf.withColumnRenamed(\"Dates\", \"Date\")\n",
    "joined_df = Nsdf.join(sgdata_sdf, on=\"Date\", how=\"inner\")\n",
    "display(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ce7fb33-e0f1-4405-908c-5618a281efb5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Downloading my spark data frame as parquet to my S3 bucket raw folder\n",
    "# joined_df.write.parquet(\"s3a://stockprediction-wg/raw/Stock_Raw_Data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8a06c71-509e-4d3b-b504-5840a28e488c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "featureAssembler = VectorAssembler(inputCols = [\"Open\",\"High\",\"Low\",\"SG-Armor\",\"SwanGuard\",\"Mkt-Trend\",\"Momentum\",\"Sentiment\"],outputCol= \"features\")# sgr armor-sentiment\n",
    "output = featureAssembler.transform(joined_df)\n",
    "# output.select(\"features\").show(5, truncate = False)\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "785e0bbf-3bd0-4873-b7b1-40b38015586a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# finanlized_data = output.select(\"Date\",\"features\",\"Close\").sort(\"Date\",ascending = True)\n",
    "# display(finanlized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16a1f927-1f50-46ef-97f2-45fd4ec1dfa5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# predicting next day close price\n",
    "# Partition the data by stock symbol and then, within each partition, order by the Date column.\n",
    "windowPartition = Window.partitionBy(\"Symbol\").orderBy(\"Date\")\n",
    "\n",
    "# Go through each partition and grab the next record's open price\n",
    "# Assign it to a new column called NextDaysOpenPrice\n",
    "df_nextday_close = output.withColumn(\"NextDaysClosePrice\", lead(\"Close\", 1).over(windowPartition))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6af338df-36cb-46fd-9838-8e2ed0019cb3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#split data for test and validation\n",
    "trainingData, testData = output.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "\n",
    "#Create linear regression\n",
    "regression = LinearRegression(featuresCol='features',labelCol='Close')# we want to precict next day close price, instead of close as label col use nextDayClosePrice\n",
    "# look up chapter 3 and 4 in machine learning in data camp \n",
    "\n",
    "# Fit the model to the training data \n",
    "model = regression.fit(trainingData)\n",
    "\n",
    "# Show model coefficients and intercept \n",
    "print(\"Coefficients: \", model.coefficients) \n",
    "print(\"Intercept: \", model.intercept) \n",
    "\n",
    "# Test the model on the testData \n",
    "test_results = model.transform(testData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f489f92-554e-4be3-98d6-185460d81df6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Show the test results \n",
    "test_results.select('Date','Open','High','Low','Close','Adj Close',\"Symbol\",'prediction').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40b8cc88-92fc-4a77-84fd-440992c5a631",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Download Model\n",
    "# test_results.write.parquet(\"s3a://stockprediction-wg/models/Stock_Prediction_Model.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c17fc96b-ec0e-4ef4-8639-3aa509575b55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluating accuracy of model using RMSE\n",
    "RegressionEvaluator(labelCol=\"Close\").evaluate(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4ee79d3-d20e-4559-ab72-a36365eeaff9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# predicting next day close price\n",
    "# Partition the data by stock symbol and then, within each partition, order by the Date column.\n",
    "windowPartition = Window.partitionBy(\"Symbol\").orderBy(\"Date\")\n",
    "\n",
    "# Go through each partition and grab the next record's open price\n",
    "# Assign it to a new column called NextDaysOpenPrice\n",
    "df_nextday_close = output.withColumn(\"NextDaysClosePrice\", lead(\"Close\", 1).over(windowPartition))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aeaca94a-e2e4-4e3d-8c57-55101188f148",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display (df_nextday_close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "921d3487-7d2b-4a12-9893-9f5e9342adfe",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d989194c-4c35-4024-9aee-edb5819e1a77",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Creating chart for closing and predicted closing \n",
    "summary_sdf = df_nextday_close.where(col(\"Symbol\") == \"MSFT\").select(\"Date\",\"Close\",\"NextDaysClosePrice\").limit(30)\n",
    "# summary_sdf=summary_sdf.dropna()\n",
    "df = summary_sdf.toPandas()\n",
    "df\n",
    "# Plotting the line chart\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.plot(df[\"Date\"], df['Close'], label='Closing Price', marker='|')\n",
    "plt.plot(df[\"Date\"], df['NextDaysClosePrice'], label='Predicted Closing Price', marker='o')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title('MSFT Closing actual price vs predicted closing (30)')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beaa83ed-e629-4b90-925a-9d8d5c2ad006",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#interesting chart 1 how does the price perform 1 year after covid \n",
    "summary_sdf = df_nextday_close \\\n",
    "    .where((col(\"Symbol\") == \"MSFT\") & (col(\"Date\") >= \"2019-12-31\") & (col(\"Date\") <= \"2021-12-31\")) \\\n",
    "    .select(\"Date\", \"Close\", \"NextDaysClosePrice\") \n",
    "# summary_sdf=summary_sdf.dropna()\n",
    "df = summary_sdf.toPandas()\n",
    "df\n",
    "# Plotting the line chart\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.plot(df[\"Date\"], df['Close'], label='Closing Price', marker='|')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title('How MSFT stock perfom from the begining of Covid')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d84dc3fd-3276-4891-a860-c2b7db9a74be",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "758b28b2-b6c9-41ca-bb61-bc48d4b236bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#interesting chart 1 how does the price perform 1 year after covid \n",
    "summary_sdf = df_nextday_close \\\n",
    "    .where((col(\"Symbol\") == \"AAPL\") & (col(\"Date\") >= \"2019-12-31\") & (col(\"Date\") <= \"2021-12-31\")) \\\n",
    "    .select(\"Date\", \"Close\", \"NextDaysClosePrice\") \n",
    "# summary_sdf=summary_sdf.dropna()\n",
    "df = summary_sdf.toPandas()\n",
    "df\n",
    "# Plotting the line chart\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.plot(df[\"Date\"], df['Close'], label='Closing Price', marker='|')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title('How MSFT stock perfom from the begining of Covid')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "550181d2-5eb6-48d8-8675-c68ff0f6186b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#interesting chart 1 how does the price perform 1 year after covid \n",
    "summary_sdf = df_nextday_close \\\n",
    "    .where((col(\"Symbol\") == \"GOOG\") & (col(\"Date\") >= \"2019-12-31\") & (col(\"Date\") <= \"2021-12-31\")) \\\n",
    "    .select(\"Date\", \"Close\", \"NextDaysClosePrice\") \n",
    "# summary_sdf=summary_sdf.dropna()\n",
    "df = summary_sdf.toPandas()\n",
    "df\n",
    "# Plotting the line chart\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.plot(df[\"Date\"], df['Close'], label='Closing Price', marker='|')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title('How Google stock perfom from the begining of Covid')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9fa53d6-1a20-4f44-8086-38bd6024cacf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#interesting chart 1 how does the price perform 1 year after covid \n",
    "summary_sdf = df_nextday_close \\\n",
    "    .where((col(\"Symbol\") == \"TSLA\") & (col(\"Date\") >= \"2019-12-31\") & (col(\"Date\") <= \"2021-12-31\")) \\\n",
    "    .select(\"Date\", \"Close\", \"NextDaysClosePrice\") \n",
    "# summary_sdf=summary_sdf.dropna()\n",
    "df = summary_sdf.toPandas()\n",
    "df\n",
    "# Plotting the line chart\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.plot(df[\"Date\"], df['Close'], label='Closing Price', marker='|')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.title('How Google stock perfom from the begining of Covid')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8f1eef3-c3b0-448a-bf9c-f8e426f94de3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "group_Data = df_nextday_close.where( (col(\"Date\") >= \"2019-12-31\") & (col(\"Date\") <= \"2023-05-11\"))\n",
    "df=group_Data.toPandas()\n",
    "\n",
    "# Group the data by StockSymbol and sum the volumes for each group\n",
    "grouped_data = df.groupby('Symbol')['Volume'].sum()\n",
    "\n",
    "# Create a stacked bar chart\n",
    "fig, ax = plt.subplots()\n",
    "grouped_data.plot(kind='bar', stacked=True, ax=ax)\n",
    "\n",
    "# Customize the chart\n",
    "ax.set_title('Volume Stack Bar Chart by Stock Symbol')\n",
    "ax.set_xlabel('Stock Symbol')\n",
    "ax.set_ylabel('Volume (in billion)')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32257a7a-8361-4ce6-8251-1b7334120829",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "grouped_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "48c76480-5f4d-4cf2-a6b8-4a1593ccd832",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "stock prediction",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
